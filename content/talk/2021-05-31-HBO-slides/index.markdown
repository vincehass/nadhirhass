---
title: Bayesian Optimization for Heteroscedastic time series
date: 2021-05-31T9:30:00
slug: 2021-05-31-HBO-slides
categories:
  - Bayesian optimization
  - Hyperparameter optimization
tags:
  - IBM
  - HPO
event: IBM-MILA colaboration
event_url: https://www-01.ibm.com/ibm/cas/canada/projects?projectId=1119
#location: Chicago, IL, USA (virtual)
subtitle: Bayesian Optimization with Surrogate Models
summary: Heteroscedastic Evolutionary Bayesian Optimization
abstract: Inspired by the increasing desire to efficiently tune machine learning hyper-parameters, in this work we rigorously analyse conventional and non-conventional assumptions inherent to Bayesian optimisation. Across an extensive set of experiments we conclude that 1) the majority of hyper-parameter tuning tasks exhibit heteroscedasticity and non-stationarity, 2) multi-objective acquisition ensembles with Pareto-front solutions significantly improve queried configurations, and 3) robust acquisition maximisation affords empirical advantages relative to its non-robust counterparts. We hope these findings may serve as guiding principles, both for practitioners and for further research in the field.
#date_end: 2020-08-31T19:40:00
all_day: no
publishDate: '2021-05-31'
featured: yes
image: 
  caption: '[Bayesian Optimization | Hyperparameter optimization| Heteroscedasticity](https://spcanelon.github.io/tour-of-the-tidyverse)'
  focal_point: center
  preview_only: no
slides: ''
projects: []
links:
- icon: images
  icon_pack: fas
  name: slides
  url: 'https://curvertino.netlify.app/pdf/Slides_HEBO_pres.pdf'
# - icon: play-circle
#   icon_pack: fas
#   name: video
#   url: https://youtu.be/m_ZoMmAIx-o
# - icon: github
#   icon_pack: fab
#   name: materials
#   url: https://github.com/spcanelon/tour-of-the-tidyverse#an-antarctic-tour-of-the-tidyverse
---

<script src="{{< blogdown/postref >}}index_files/fitvids/fitvids.min.js"></script>

## Description

Explore how to handle non-linear transformations in a heteroscedastic time series settings, this will avoid Multi-objectivity conflicts and enables a consensus among various acquisition functions through a Pareto-frontier.
<br><br>

<!-- ## Slides

<div class="shareagain" style="min-width:300px;margin:1em auto;">
<iframe src="https://github.com/vincehass/ML-Domain-Based-archive/blob/main/Bayesian%20Optimization/Slides_HEBO_pres.pdf" width="1600" height="900" style="border:2px solid currentColor;" loading="lazy" allowfullscreen></iframe>
<script>fitvids('.shareagain', {players: 'iframe'});</script>
</div> -->
